{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a96284-7629-4380-ad17-aa659f63c7a2",
   "metadata": {},
   "source": [
    "# Foundations to AI\n",
    "\n",
    "CSI 4106 - Fall 2024\n",
    "\n",
    "Marcel Turcotte  \n",
    "Version: Sep 9, 2024 08:36\n",
    "\n",
    "# Preamble\n",
    "\n",
    "## Quote of the day\n",
    "\n",
    "We are assembling **a lean, cracked team of the world’s best engineers\n",
    "and researchers** dedicated to focusing on SSI (safe superintelligence)\n",
    "and nothing else.\n",
    "\n",
    "[ssi.inc](https://ssi.inc)\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Understanding the **history of artificial intelligence** is crucial,\n",
    "especially now as we find ourselves at the **peak of speculative\n",
    "enthusiasm**, with widespread claims that the era of **general\n",
    "artificial intelligence is imminent**.\n",
    "\n",
    "For individuals not formally trained in artificial intelligence, the\n",
    "current widespread enthusiasm might suggest we are on the cusp of a\n",
    "significant transformative era.\n",
    "\n",
    "Research in artificial intelligence has historically progressed in a\n",
    "manner more aligned with the chronological development of **philosophy**\n",
    "rather than the **evolutionary trajectory of biological intelligence**.\n",
    "Had AI research mirrored the evolutionary stages of intelligence, we\n",
    "would have first developed systems with **nematode-level intelligence**\n",
    "focused on basic steering mechanisms. This would have been followed by\n",
    "models emulating **early vertebrates** utilizing reinforcement learning,\n",
    "then **early mammals** capable of world simulation, **early primates**\n",
    "with mentalizing abilities, and ultimately **human-like intelligence**\n",
    "characterized by advanced communication skills.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "<https://youtu.be/HAiXT1mGTXc>\n",
    "\n",
    "-   The **initial 18 minutes** of this 47-minute video provide a\n",
    "    **historical overview of artificial intelligence**.\n",
    "\n",
    "-   **Melanie Mitchell** is a prominent figure in contemporary\n",
    "    discussions on artificial intelligence, particularly critiquing the\n",
    "    benchmarks employed to evaluate software systems.\n",
    "\n",
    "-   Understanding the **history of artificial intelligence** is crucial,\n",
    "    especially now as we find ourselves at the **peak of speculative\n",
    "    enthusiasm**, with widespread claims that the era of **general\n",
    "    artificial intelligence is imminent**.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "-   **Recognize** the contributions of other disciplines to AI.\n",
    "-   **Situate** current AI within its historical context.\n",
    "-   **Introducing** some of the tools, namely Jupyter Notebooks.\n",
    "\n",
    "In the same spirit as the first course presentation, the first two parts\n",
    "of our agenda today will be relatively general, aiming to contextualize\n",
    "artificial intelligence (AI). Although our course is highly technical,\n",
    "it is essential to understand that AI is inherently multidisciplinary.\n",
    "\n",
    "In our evaluations, I will not require you to memorize the names of\n",
    "individuals who contributed to the foundation of AI. The first two\n",
    "lectures are intended to provide context.\n",
    "\n",
    "Towards the end of the semester, I would appreciate your feedback on the\n",
    "effectiveness of these lectures. I may organize a pizza lunch to discuss\n",
    "what aspects are working, what are not, what is missing, and what should\n",
    "be removed.\n",
    "\n",
    "## Schools (from the first lecture)\n",
    "\n",
    "-   **Symbolic AI** (includes approaches based on logic)\n",
    "-   **Connectionists** (mostly neural networks)\n",
    "\n",
    "Long seen as mutually exclusive.\n",
    "\n",
    "As discussed in our first lecture, there are two principal paradigms in\n",
    "artificial intelligence: **symbolic AI** and **connectionism**. While\n",
    "the symbolic approach originally dominated the field, the connectionist\n",
    "approach is now more prevalent.\n",
    "\n",
    "Consider this context as we examine the brief history of artificial\n",
    "intelligence.\n",
    "\n",
    "# Foundations of Artificial Intelligence\n",
    "\n",
    "In the first lecture, we explored various approaches to constructing\n",
    "artificial intelligence systems, including human-like thinking,\n",
    "human-like behavior, rational thinking, and rational behavior.\n",
    "\n",
    "CSI 4106 provides a computer science perspective on artificial\n",
    "intelligence.\n",
    "\n",
    "However, it is important to acknowledge that the development of\n",
    "artificial intelligence is a multidisciplinary endeavor, with each field\n",
    "offering its own unique insights.\n",
    "\n",
    "## Philosophy\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/a/ae/Aristotle_Altemps_Inv8575.jpg)\n",
    "\n",
    "**Aristotle** (**384-322 BC**) laid several foundational concepts for\n",
    "AI, including an informal system of syllogisms that facilitates proper\n",
    "**reasoning** by **mechanically deriving conclusions from given\n",
    "premises**.\n",
    "\n",
    "**Attribution:** [After\n",
    "Lysippos](https://commons.wikimedia.org/wiki/File:Aristotle_Altemps_Inv8575.jpg),\n",
    "Public domain, via Wikimedia Commons.\n",
    "\n",
    "Symbolic AI has been profoundly influenced by logic, which traces its\n",
    "origins back to Greek philosophy.\n",
    "\n",
    "A notable example is the [General Problem\n",
    "Solver](https://en.wikipedia.org/wiki/General_Problem_Solver), developed\n",
    "by [Herbert A. Simon](https://en.wikipedia.org/wiki/Herbert_A._Simon)\n",
    "and [Allen Newell](https://en.wikipedia.org/wiki/Allen_Newell) in 1957.\n",
    "\n",
    "Numerous philosophers, including , contributed to the body of work that\n",
    "laid the foundation for AI.\n",
    "\n",
    "Numerous philosophers, including David Hume (Hume (\\[1739\\] 1739)), have\n",
    "significantly contributed to the foundational theories underlying\n",
    "artificial intelligence (AI).\n",
    "\n",
    "The connection between contemporary artificial intelligence (AI) and\n",
    "philosophy is profound, encompassing foundational, ethical,\n",
    "epistemological, and metaphysical dimensions. Philosophers and AI\n",
    "researchers jointly explore the **nature of intelligence**, **ethical\n",
    "deployment of AI**, **knowledge representation**, and the **transparency\n",
    "of AI systems**. They address the societal impacts of AI, including\n",
    "**labor market changes** and **autonomous decision-making**, while\n",
    "engaging in interdisciplinary dialogue to ensure AI technologies align\n",
    "with human values and societal goals. This collaboration fosters the\n",
    "development of robust, ethical, and **socially responsible AI systems**.\n",
    "\n",
    "## Philosophy (continued)\n",
    "\n",
    "**Utilitarianism** is an ethical theory that emphasizes the **greatest\n",
    "good for the greatest number**.\n",
    "\n",
    "1.  Utilitarianism offers AI a **decision-making framework** by\n",
    "    prioritizing actions that enhance collective well-being.\n",
    "2.  It guides the **ethical design of AI** to ensure technology promotes\n",
    "    societal welfare.\n",
    "3.  Utilitarianism directs **efficient resource distribution** in AI,\n",
    "    targeting maximal positive impact, especially in sectors like\n",
    "    healthcare.\n",
    "4.  It shapes **policy and regulation** to maximize societal benefits\n",
    "    and minimize AI-related harms.\n",
    "5.  Utilitarian principles assist in **balancing AI’s benefits against\n",
    "    risks for a net positive outcome**.\n",
    "\n",
    "Jeremy **Bentham** (1823) and John Stuart **Mill** (1863).\n",
    "\n",
    "## Mathematics – formal logic\n",
    "\n",
    "-   **George Boole** (1815–1864) is credited with the mathematization of\n",
    "    logic through the development of **propositional logic**, also\n",
    "    referred to as boolean logic.\n",
    "-   **Gottlob Frege** (1848–1925) extended Boole’s logical framework by\n",
    "    incorporating objects and relations, thereby developing what is now\n",
    "    known as **first-order logic**.\n",
    "-   The contributions of Kurt **Gödel** (1906–1978), Alonzo **Church**\n",
    "    (1903–1995), and Alan **Turing** (1912–1954), among others, have\n",
    "    been instrumental in shaping the modern concept of **computation**.\n",
    "\n",
    "## Mathematics – probability\n",
    "\n",
    "-   Gerolamo **Cardano** (1501–1576) initially conceptualized\n",
    "    **probability** through gambling outcomes.\n",
    "-   Blaise **Pascal** (1623–1662) outlined methods in 1654 for\n",
    "    **calculating predictions** and average payoffs in unfinished\n",
    "    gambling games in correspondence with Pierre Fermat (1601–1665).\n",
    "-   Thomas **Bayes** (1702–1761) introduced a method for **revising\n",
    "    probabilities with new evidence**, known as Bayes’ rule, vital for\n",
    "    AI applications.\n",
    "\n",
    "## Mathematics – algorithms\n",
    "\n",
    "-   Complex **algorithms** have their origins with **Euclid** around\n",
    "    **300 BC**, while the term “**algorithm**” itself is derived from\n",
    "    the work of **Muhammad ibn Musa al-Khwarizmi** in the 9th century.\n",
    "\n",
    "-   The **Church-Turing thesis** posits that any **computation** that\n",
    "    can be performed by a mechanical process can be computed by a\n",
    "    **Turing machine**, essentially equating the concept of algorithmic\n",
    "    computation with the capabilities of Turing machines (Church 1936;\n",
    "    Alan M. Turing 1936).\n",
    "\n",
    "-   The concept of **NP-completeness**, introduced by **Cook** and\n",
    "    further developed by **Karp**, establishes a framework for\n",
    "    evaluating the **tractability** of computational problems. (Cook\n",
    "    1971; Karp 1972)\n",
    "\n",
    "## Neuroscience\n",
    "\n",
    "Today, it is universally acknowledged that cognitive functions emerge\n",
    "from the **electrochemical activities** within these **brain\n",
    "structures**, illustrating how assemblies of simple cells can give rise\n",
    "to **thought**, **action**, and **consciousness**.\n",
    "\n",
    "## Neuroscience (continued)\n",
    "\n",
    "-   “Of all the animals, man has the largest brain in proportion to his\n",
    "    size.” **Aristotle**, **335** BC.\n",
    "-   Paul **Broca**’s research in **1861** marked the beginning of\n",
    "    understanding the brain’s **functional organization**, notably\n",
    "    identifying the left hemisphere’s role in speech production.\n",
    "\n",
    "## Neuroscience (continued)\n",
    "\n",
    "Large-scale collaborative studies have provided us with extensive data\n",
    "encompassing the **anatomy**, **cell types**, **connectivity**, and\n",
    "**gene expression** profiles of the **brain** (Maroso 2023; Conroy\n",
    "2023).\n",
    "\n",
    "-   [Allen Brain Atlas](https://portal.brain-map.org)\n",
    "-   [Brain Initiative Alliance](https://www.braininitiative.org)\n",
    "-   [Brain Cell Census - A Collection from Science’s\n",
    "    Journals](https://www.science.org/collections/brain-cell-census)\n",
    "\n",
    "## Neuroscience – neuron\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/3/36/Components_of_neuron.jpg)\n",
    "\n",
    "**Attribution:** Jennifer Walinga, [CC BY-SA\n",
    "4.0](https://creativecommons.org/licenses/by-sa/4.0)\n",
    "\n",
    "The development of **artificial neural networks** (AKA **neural\n",
    "networks** or **neural nets**, abbreviated as ANN or NN; ANNs or NNs)\n",
    "has been inspired by the structure and function of biological neural\n",
    "networks in animals.\n",
    "\n",
    "Yann LeCun and other authors have often stated that our artificial\n",
    "neural networks used in machine learning resemble biological neural\n",
    "networks in the same way that an airplane’s wings resemble a bird’s\n",
    "wings.\n",
    "\n",
    "## Computers vs human brain\n",
    "\n",
    "|                  | Supercomputer         | Personal Computer     | Human Brain        |\n",
    "|----------------|-------------------|---------------------|-----------------|\n",
    "| Processing units | $10^6$ CPU+GPU cores  | 8 CPU cores           | $10^6$ columns     |\n",
    "|                  | $10^{15}$ transistors | $10^{15}$ transistors | $10^{11}$ neurons  |\n",
    "|                  |                       |                       | $10^{14}$ synapses |\n",
    "| Cycle time       | $10^{-9}$ sec         | $10^{-9}$ sec         | $10^{-3}$ sec      |\n",
    "| Operations/sec   | $10^{18}$             | $10^{10}$             | $10^{17}$          |\n",
    "\n",
    "**Adapted from:** Russell and Norvig (2020)\n",
    "\n",
    "Internet rumors suggest that “GPT-4 has approximately 1.8 trillion\n",
    "parameters distributed across 120 layers” and that “OpenAI utilizes 16\n",
    "experts within their model, each with around 111 billion parameters for\n",
    "the MLP” [GPT-4 architecture, datasets, costs, and more\n",
    "leaked](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/)\n",
    "(Maximilian Schreiner, The Decoder, July 11, 2023).\n",
    "\n",
    "Why are these figures significant? Improvements in performance can be\n",
    "achieved through the use of more data, larger models, and different\n",
    "training algorithms.\n",
    "\n",
    "The instructor’s laptop:\n",
    "\n",
    "|        |                                                                                                |\n",
    "|------|------------------------------------------------------------------|\n",
    "| M2 Max | 12 CPU cores, 30 GPU cores, $6.7 \\times 10^{10}$ transistors, $3.49 \\times 10^{-9}$ clock rate |\n",
    "|        | $6.4 \\times 10^{10}$ (64G) bytes RAM                                                           |\n",
    "|        | $2 \\times 10^{12}$ (2 T) bytes disk                                                            |\n",
    "|        | 16-core Neural Engine executing 15.8 trillion ($1.58 \\times 10^{13}$) operations per seconds.  |\n",
    "\n",
    "## Computers vs human brain (contd)\n",
    "\n",
    "-   “By the end of 2024, we’re aiming to continue to grow our\n",
    "    infrastructure build-out that will include **350,000 NVIDIA H100\n",
    "    GPUs** as part of **a portfolio that will feature compute power\n",
    "    equivalent to nearly 600,000 H100s**.”\n",
    "    -   [Building Meta’s GenAI\n",
    "        Infrastructure](https://engineering.fb.com/2024/03/12/data-center-engineering/building-metas-genai-infrastructure/),\n",
    "        March 12,2024.\n",
    "    -   Each H100 has 80 billion ($8 \\times 10^{10}$) transistors.\n",
    "    -   600,000 H100s implies a total of $4.8 \\times 10^{16}$\n",
    "        transistors.\n",
    "    -   Each chip carries a price tag of \\$40,000 USD!\n",
    "    -   \\$24,000,000,000 (24 billion) USD infrastructure.\n",
    "        -   Similar to Iceland’s Gross Domestic Product (GDP).\n",
    "\n",
    "One can only imagine the energy counsumption of such compute system!\n",
    "\n",
    "NVDIA’s next generation of GPUs, Blackwell B200, has 208 billion\n",
    "transistors.\n",
    "\n",
    "## Computers vs human brain (contd)\n",
    "\n",
    "-   “By combining this data, de Vries calculates that **by 2027 the AI\n",
    "    sector could consume between 85 to 134 terawatt hours each year**.\n",
    "    That’s about the **same as the annual energy demand** of de Vries’\n",
    "    home country, the **Netherlands**.”\n",
    "    -   [How much electricity does AI\n",
    "        consume?](https://www.theverge.com/24066646/ai-electricity-energy-watts-generative-consumption)\n",
    "        The Verge, February 16, 2024\n",
    "\n",
    "## Psychology\n",
    "\n",
    "> ** (Craik 1943)**\n",
    ">\n",
    "> If the organism carries a “small-scale model” of external reality and\n",
    "> of its own possible **actions** within its head, it is able to **try\n",
    "> out various alternatives**, conclude which is the best of them,\n",
    "> **react** to future situations before they arise, utilize the\n",
    "> knowledge of past events in dealing with the present and future, and\n",
    "> in every way to react in a much fuller, safer, and more competent\n",
    "> manner to the emergencies which face it.\n",
    "\n",
    "-   **Cognitive psychology** conceptualizes the brain as an\n",
    "    **information-processing device**.\n",
    "\n",
    "-   **Knowledge-based agents** are conceptualized as receiving inputs\n",
    "    (percepts) from their environment, having an internal state, and\n",
    "    producting actions (outputs).\n",
    "\n",
    "## Cognitive science\n",
    "\n",
    "In the same year that the term **“artificial intelligence”** was\n",
    "introduced, **cognitive science** emerged as a discipline.\n",
    "\n",
    "1956 MIT workshop:\n",
    "\n",
    "-   George **Miller**, *The Magic Number Seven* (Miller 1956)\n",
    "-   Noam **Chomsky**, *Three Models of Language* (Chomsky 1956)\n",
    "-   Allen **Newell** and Herbert **Simon**, *The Logic Theory Machine*\n",
    "    (A. Newell and Simon 1956)\n",
    "\n",
    "Three foundational papers demonstrated how **computer models** can be\n",
    "applied to the **psychology of memory**, **language**, and **logical\n",
    "reasoning**.\n",
    "\n",
    "# Artificial Intelligence: A Timeline\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "1943–1974\n",
    "\n",
    "## 1950 – Turing test\n",
    "\n",
    "The **Turing Test** is a measure of a machine’s ability to exhibit\n",
    "intelligent **behavior** **indistinguishable** from that of a human.\n",
    "\n",
    "If a **human evaluator** **cannot reliably distinguish** between a\n",
    "**machine** and a **human** based solely on their responses to\n",
    "questions, **the machine is said to have passed the test**.\n",
    "\n",
    "A. M. Turing (1950)\n",
    "\n",
    "## 1950 – Turing test (in 2024)\n",
    "\n",
    "> ** (Mitchell 2024)**\n",
    ">\n",
    "> It’s likely that **the Turing Test will become yet another casualty of\n",
    "> our shifting conceptions of intelligence**. In 1950, Turing intuited\n",
    "> that the ability for human-like conversation should be firm evidence\n",
    "> of “thinking,” and all that goes with it. That intuition is still\n",
    "> strong today. But perhaps what we have learned from ELIZA and Eugene\n",
    "> Goostman, and what we may still learn from ChatGPT and its ilk, is\n",
    "> that **the ability to sound fluent in natural language**, like playing\n",
    "> chess, **is not conclusive proof of general intelligence**.\n",
    "\n",
    "1.  This quote refers to the AI effect, which states that ($\\ldots$) as\n",
    "    soon as a computer system is built to solve a problem successfully,\n",
    "    the problem is no longer “only solvable by the human mind,”\n",
    "    (McCorduck 2004)\n",
    "2.  Furthermore, recent research in neuro science suggests that “the\n",
    "    brain networks underlying what they call “formal linguistic\n",
    "    competence”—the abilities related to language production—are largely\n",
    "    separate from the networks underlying common sense, reasoning, and\n",
    "    other aspects of what we might call “thinking.”” (Mitchell 2024)\n",
    "\n",
    "> ** (Mitchell 2024)**\n",
    ">\n",
    "> However, if the history of AI has taught us anything, it’s that our\n",
    "> intuitions are often wrong about such assumptions. Decades ago, many\n",
    "> prominent AI experts believed that creating a machine that could beat\n",
    "> humans at chess would require something equivalent to full human\n",
    "> intelligence. “If one could devise a successful chess machine, one\n",
    "> would seem to have penetrated to the core of human intellectual\n",
    "> endeavor,” [wrote](http://iiif.library.cmu.edu/file/Newell_box00038_fld02730_doc0001/Newell_box00038_fld02730_doc0001.pdf) AI\n",
    "> pioneers Allen Newell and Herbert Simon in 1958, and cognitive\n",
    "> scientist Douglas\n",
    "> Hofstadter [predicted](https://www.hachettebookgroup.com/titles/douglas-r-hofstadter/godel-escher-bach/9780465026562/?lens=basic-books) in\n",
    "> 1979 that in the future, “there may be programs which can beat anyone\n",
    "> at chess, but…they will be programs of *general* intelligence.”\n",
    "\n",
    "## 1943 – First artificial neural network\n",
    "\n",
    "Warren S. **McCulloch** & Walter **Pitts** 1943\n",
    "\n",
    "-   **Propositional Logic and Neural Events:** The “all-or-none” nature\n",
    "    of nervous activity allows neural events and their relationships to\n",
    "    be treated using propositional logic.\n",
    "-   **Implications for Psychology and Neurophysiology:** The theory\n",
    "    provides a rigorous framework for understanding mental activities in\n",
    "    terms of neurophysiology, offering insights into the causal\n",
    "    relationships and the construction of hypothetical neural nets.\n",
    "-   **Learning:** we regard $(\\ldots)$ learning as an enduring change\n",
    "    which can survive sleep, anaesthesia, convulsions and coma.\n",
    "\n",
    "McCulloch and Pitts (1943)\n",
    "\n",
    "The paper focuses on the equivalence between neural networks and\n",
    "propositional logic. Showeing that **any computable function** could be\n",
    "computed by some network of connected neurons.\n",
    "\n",
    "Defines learning as change, but does not provide an algorithm for\n",
    "learning.\n",
    "\n",
    "## 1949 – First artificial neural network\n",
    "\n",
    "In 1949, Donald **Hebb** introduced a straightforward updating rule for\n",
    "adjusting the connection strengths between neurons.\n",
    "\n",
    "**Hebbian learning** is a learning mechanism in which the synaptic\n",
    "strength between two neurons is increased if they are activated\n",
    "simultaneously. This principle is often summarized as “**cells that fire\n",
    "together, wire together**,” and it forms the basis for understanding how\n",
    "neural connections are reinforced through experience.\n",
    "\n",
    "## 1950 – First artificial neural network\n",
    "\n",
    "-   In **1950**, while an undergraduate at Harvard, Marvin Minsky, in\n",
    "    collaboration with Dean Edmonds, constructed the **first artificial\n",
    "    neural network computer**, which simulated the functionality of **40\n",
    "    neurons**.\n",
    "-   In **1954**, for his doctoral thesis in mathematics at Princeton\n",
    "    University, Minsky conducted an in-depth investigation into the\n",
    "    principle of **universal computation within neural networks**.\n",
    "\n",
    "## First artificial neural network\n",
    "\n",
    "<https://youtu.be/cNxadbrN_aI>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b86fdac-1dfd-4c80-953c-1952173e816f",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<!--# See also: https://www.youtube.com/watch?v=Suevq-kZdIw \n",
    "    aspect-ratio=\"21x9\" \n",
    "    width=\"80%\" height=\"100%\" \n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22592b29-18a8-4b24-b032-1188164f7349",
   "metadata": {},
   "source": [
    "-   [The Machine That Changed the World - TV Series -\n",
    "    1992](https://www.imdb.com/title/tt1245829/)\n",
    "\n",
    "It is observed that artificial neural networks were introduced very\n",
    "early, and as early as the 1960s, they were not considered promising.\n",
    "Additionally, biases in the datasets used for training these networks\n",
    "were already noticeable.\n",
    "\n",
    "## 1956 – Founding event\n",
    "\n",
    "> ** Dartmouth Summer Research Project on Artificial Intelligence**\n",
    ">\n",
    "> We propose that a **2-month**, **10-man** study of **artificial\n",
    "> intelligence** be carried out during the summer of 1956 at Dartmouth\n",
    "> College in Hanover, New Hampshire. The study is to proceed on the\n",
    "> basis of the conjecture that **every aspect of learning or any other\n",
    "> feature of intelligence can in principle be so precisely described\n",
    "> that a machine can be made to simulate it**. An attempt will be made\n",
    "> to find how to make machines use language, form abstractions and\n",
    "> concepts, solve kinds of problems now reserved for humans, and improve\n",
    "> themselves. We think that a <u>**significant advance can be made in\n",
    "> one or more of these problems if a carefully selected group of\n",
    "> scientists work on it together for a summer**.</u>\n",
    "\n",
    "-   Proposed by John **McCarthy**, Marvin **Minsky**, Nathaniel\n",
    "    **Rochester**, and Claude **Shannon**. Participants also included\n",
    "    Allen **Newell** and Herbert **Simon**.\n",
    "\n",
    "-   Acknowledged as the **first usage** of the term **“artificial\n",
    "    intelligence.”**\n",
    "\n",
    "-   John McCarthy, who was part of the Mathematics Department at\n",
    "    Dartmouth College, not only coined the term “**artificial\n",
    "    intelligence**” but also developed **Lisp**.\n",
    "\n",
    "    -   This general-purpose programming language remained predominant\n",
    "        in the AI field for over three decades. Lisp introduced several\n",
    "        groundbreaking concepts, such as **garbage collection**,\n",
    "        **dynamic typing**, **higher-order functions**, **recursion**,\n",
    "        the **read-eval-print loop**, and the **self-hosting compiler**,\n",
    "        significantly influencing the development of programming\n",
    "        languages.\n",
    "\n",
    "## 1956 – Logic Theorist\n",
    "\n",
    "> ** Russell and Norvig (2020)**\n",
    ">\n",
    "> Newell and Simon presented perhaps the most mature work, a\n",
    "> mathematical theorem-proving system called the **Logic Theorist**\n",
    "> (LT). Simon claimed, **‘We have invented a computer program capable of\n",
    "> thinking non-numerically, and thereby solved the venerable mind–body\n",
    "> problem.’**\n",
    "\n",
    "## 1959 – Machine Learning\n",
    "\n",
    "Arthur **Samuel**’s work on machine learning using the game of checkers\n",
    "has had a profound impact on the field of artificial intelligence (AI)\n",
    "and computer science at large.\n",
    "\n",
    "-   One of the earliest examples of a **self-improving AI system**.\n",
    "-   His contributions helped to establish **machine learning** as a\n",
    "    critical sub-field of AI.\n",
    "-   Samuel defines machine learning as a “**field of study that gives\n",
    "    computers the ability to learn without being explicitly\n",
    "    programmed**”.\n",
    "-   Precursor to **reinforcement learning** and **AlphaGo**.\n",
    "\n",
    "Samuel (1959), also featured in this 53 minutes video: [“The Thinking\n",
    "Machine” (1961) - MIT Centennial\n",
    "Film](https://www.youtube.com/watch?v=cvOTKFXpvKA)\n",
    "\n",
    "## 1952 - IBM 701\n",
    "\n",
    "-   16,000 instructions per second\n",
    "-   8.75 kilobytes of memory\n",
    "\n",
    "<!--#![](https://imageio.forbes.com/specials-images/imageserve/60b13f395e70ff270e5f6bc0/Arthur-Samuel-and-his-checkers-playing-IBM-computer-in-1956/960x0.jpg)-->\n",
    "\n",
    "**Attribution:** [IBM Watson\n",
    "Media](https://artsandculture.google.com/asset/arthur-samuel-demonstrates-how-machine-learning-can-be-used-to-play-checkers-in-1962-ibm-watson-media/vgH46mpas8dL4g)\n",
    "\n",
    "The 701 was one million times slower than a 2020 desktop computer and\n",
    "one hundred trillion slower than today’s supercomputers.\n",
    "\n",
    "## Hype\n",
    "\n",
    "> ** 1957 Herbert Simon**\n",
    ">\n",
    "> It is not my aim to surprise or shock you—but the simplest way I can\n",
    "> summarize is to say that **there are now in the world machines that\n",
    "> think, that learn and that create**. Moreover, their ability to do\n",
    "> these things is going to increase rapidly until—in a visible\n",
    "> future—**the range of problems they can handle will be coextensive\n",
    "> with the range to which the human mind has been applied**.\n",
    "\n",
    "> ** 1958, New York Times, July 8**\n",
    ">\n",
    "> The Navy revealed the embryo of an electronic computer today that it\n",
    "> expects will be able to **walk**, **talk**, **see**, **write**,\n",
    "> **reproduce itself**, and be **conscious** of its existence.\n",
    "\n",
    "> ** 1965 Herbert Simon (Mitchell 2019)**\n",
    ">\n",
    "> ($\\ldots$) machines will be capable, **within 20 years**, of doing any\n",
    "> work that a man can do.\n",
    "\n",
    "> ** 1966 Marvin Minsky (Mitchell 2019)**\n",
    ">\n",
    "> ($\\ldots$) in which they would assign undergraduates to work on “the\n",
    "> construction of a significant part of a visual system.” In the words\n",
    "> of one AI historian, “Minsky hired a **first-year undergraduate** and\n",
    "> assigned him **a problem to solve over the summer**: connect a\n",
    "> television camera to a computer and **get the machine to describe what\n",
    "> it sees**.”\n",
    "\n",
    "> ** 1967 Marvin Minsky (Strickland 2021)**\n",
    ">\n",
    "> Within **a generation**$\\ldots$ the problem of creating ‘**artificial\n",
    "> intelligence**’ will be substantially **solved**.\n",
    "\n",
    "Marvin Minsky’s citation is particularly noteworthy. Like the other\n",
    "citations, it exudes enthusiasm. However, what stands out is the\n",
    "realization that problems we now take for granted, such as image\n",
    "classification, were once considered simple. This led Steven Pinker to\n",
    "write in 1994: “The main lesson of thirty-five years of AI research is\n",
    "that the hard problems are easy and the easy problems are hard.”\n",
    "Similarly, in 1988, Hans Moravec observed: “It is comparatively easy to\n",
    "make computers exhibit adult-level performance on intelligence tests or\n",
    "in playing checkers, yet difficult or impossible to endow them with the\n",
    "perceptual and mobility skills of a one-year-old.”\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "1974–1980\n",
    "\n",
    "## Symbolic AI\n",
    "\n",
    "In 1976, Newell and Simon, the authors of Logic Theorist (LT) create the\n",
    "**General Problem Solver (GPS)** meant to emulate how human solve\n",
    "problems.\n",
    "\n",
    "> ** Allen Newell and Simon (1976)**\n",
    ">\n",
    "> a **physical symbol system** has the **necessary** and **sufficient**\n",
    "> means for general intelligent action.\n",
    "\n",
    "## First AI winter.\n",
    "\n",
    "Funding dried up.\n",
    "\n",
    "> ** Russell and Norvig (2020)**\n",
    ">\n",
    "> Failure to come to grips with the **“combinatorial explosion”** was\n",
    "> one of the main criticisms of AI contained in the Lighthill report\n",
    "> (Lighthill, 1973), which formed the basis for the **decision by the\n",
    "> British government to end support for AI research** in all but two\n",
    "> universities.\n",
    "\n",
    "Fundamental limitations: what could be represented. Linearly separable\n",
    "data, for instance.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "1980–1987\n",
    "\n",
    "## Expert systems\n",
    "\n",
    "**Expert systems** are programs that emulate the decision-making\n",
    "abilities of a human expert by using a **knowledge base** and\n",
    "**inference rules** (typically, **if-then** rules) to solve complex\n",
    "problems within a **specific domain.**\n",
    "\n",
    "-   1984, Douglas **Lenat** began work on **Cyc**, with the aim to\n",
    "    encode human common sense. By 2017, Cyc had **1.5 million terms**\n",
    "    and **24.5 million rules**.\n",
    "\n",
    "Expert systems were formally introduced around 1965 by Edward\n",
    "**Feigenbaum**, who is sometimes termed the “father of expert\n",
    "systems”; other key early contributors were Bruce **Buchanan** and\n",
    "Randall **Davis**.\n",
    "\n",
    "Examples include:\n",
    "\n",
    "-   MYCIN, an early backward chaining expert system, utilized artificial\n",
    "    intelligence to identify bacteria responsible for severe infections\n",
    "    like bacteremia and meningitis. It also recommended appropriate\n",
    "    antibiotics, with dosages adjusted based on the patient’s body\n",
    "    weight. Its knowledge-base was comprised of approximately 600 rules.\n",
    "    1975, written in Lisp.\n",
    "-   Dendral assisted chemists in identifying unknown organic molecules\n",
    "    by analyzing their mass spectra and leveraging chemical knowledge.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "-   Explicit representation of the knowledge;\n",
    "-   Knowledge separate from the reasoning engine;\n",
    "-   Explanability.\n",
    "\n",
    "**Disadvantages:**\n",
    "\n",
    "-   Superficial and incomplete knowledge\n",
    "-   Data acquisition is very hard, and usually hand coded by domain\n",
    "    experts.\n",
    "-   Combinatorial explosion leading huge runtime.\n",
    "-   Limited reasoning under uncertainty or contradictory information.\n",
    "\n",
    "## Expert systems - if-then rules\n",
    "\n",
    "**Rule 1:** - **IF** the patient has a fever AND the patient has a sore\n",
    "throat, - **THEN** consider the possibility of a streptococcal\n",
    "infection.\n",
    "\n",
    "**Rule 2:** - **IF** the patient has a rash AND the patient has been in\n",
    "a wooded area recently, - **THEN** consider the possibility of Lyme\n",
    "disease.\n",
    "\n",
    "**Rule 3:** - **IF** the patient is experiencing chest pain AND the\n",
    "patient has a history of heart disease, - **THEN** consider the\n",
    "possibility of a myocardial infarction (heart attack).\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "1987–1993\n",
    "\n",
    "## Second AI winter\n",
    "\n",
    "> ** Strickland (2021)**\n",
    ">\n",
    "> By the 1990s, it was no longer academically fashionable to be working\n",
    "> on either **symbolic AI** or **neural networks**, because **both\n",
    "> strategies seemed to have flopped**.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "1993–2011\n",
    "\n",
    "## Support Vector Machine (SVM)\n",
    "\n",
    "-   A **Support Vector Machine (SVM)** is a supervised **machine\n",
    "    learning** algorithm.\n",
    "-   It operates by identifying the optimal **hyperplane** that separates\n",
    "    data into distinct classes within a high-dimensional space.\n",
    "-   Grounded in the robust theoretical framework of Vapnik-Chervonenkis\n",
    "    **(VC) theory**.\n",
    "-   Influential and dominant during the **1990s** and **2000s**.\n",
    "\n",
    "Boser, Guyon, and Vapnik (1992)\n",
    "\n",
    "SVM, a blow to connectionists.\n",
    "\n",
    "SVM is still an excellent choice of classifier.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "2011–\n",
    "\n",
    "## Deep learning\n",
    "\n",
    "In 2012, **AlexNet**, a **convolutional neural network (CNN)**\n",
    "architecture inspired by **Yann LeCun**’s work, wins the **ImageNet\n",
    "Large Scale Visual Recognition Challenge**.\n",
    "\n",
    "This marked a pivotal moment in the field, as subsequently, all leading\n",
    "entries in the competition have been founded on deep learning\n",
    "methodologies.\n",
    "\n",
    "Krizhevsky, Sutskever, and Hinton (2012)\n",
    "\n",
    "The success of deep learning is generally attributed to the following:\n",
    "\n",
    "-   **Big data**: The proliferation of big data from various sources,\n",
    "    such as social media, sensors, and digital repositories, provides\n",
    "    the extensive datasets necessary for training deep learning models.\n",
    "-   **GPUs and TPUs**: The advent of powerful Graphics Processing Units\n",
    "    (GPUs) and Tensor Processing Units (TPUs) has significantly\n",
    "    accelerated the training and inference processes for large neural\n",
    "    networks.\n",
    "-   **Improved Training Algorithms:**\n",
    "    -   **Optimization Techniques:** Enhanced optimization algorithms\n",
    "        like Adam, RMSprop, and momentum-based approaches have improved\n",
    "        the efficiency and convergence of deep learning models.\n",
    "    -   **Regularization Methods:** Techniques such as L2\n",
    "        regularization, dropout, and data augmentation have helped\n",
    "        prevent overfitting and improved generalization.\n",
    "\n",
    "## Winter is coming?\n",
    "\n",
    "<https://youtu.be/dx-tMK7w5g8>\n",
    "\n",
    "## Summary\n",
    "\n",
    "![](https://www.actuaries.digital/wp-content/uploads/2018/08/ai1.jpg)\n",
    "\n",
    "**See also:**\n",
    "\n",
    "-   [15 Graphs That Explain the State of AI in\n",
    "    2024](https://spectrum.ieee.org/ai-index-2024), Eliza Strickland,\n",
    "    IEEE Spectrum, April 2024.\n",
    "\n",
    "**Attribution:** [History of AI\n",
    "Winters](https://www.actuaries.digital/2018/09/05/history-of-ai-winters/)\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "## Requirements\n",
    "\n",
    "Proficiency in **Python** is expected.\n",
    "\n",
    ". . .\n",
    "\n",
    "For those needing a refresher, the **official tutorial** on\n",
    "[**Python.org**](https://docs.python.org/3/tutorial/index.html) is a\n",
    "good place to start.\n",
    "\n",
    ". . .\n",
    "\n",
    "Simultaneously enhance your skills by creating a **Jupyter Notebook**\n",
    "that incorporates examples and notes from the **tutorial**.\n",
    "\n",
    ". . .\n",
    "\n",
    "**Other resources include:**\n",
    "\n",
    "-   [Stanford CS231n Python Tutorial with Google\n",
    "    Colab](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb)\n",
    "-   [Advanced Python\n",
    "    Tutorial](https://colab.research.google.com/drive/1gCqFEquqNvEoTDX3SNhR2PZkXWPHKXnc?usp=sharing)\n",
    "\n",
    "[Stanford CS231n Python Tutorial with Google\n",
    "Colab](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb):\n",
    "This link directs you to a Python tutorial presented in a Jupyter\n",
    "Notebook format, which can be executed within the Google Colab\n",
    "environment. Additional details are provided below.\n",
    "\n",
    "Finally, here is an [Advanced Python\n",
    "Tutorial](https://colab.research.google.com/drive/1gCqFEquqNvEoTDX3SNhR2PZkXWPHKXnc?usp=sharing)\n",
    "provided by Google.\n",
    "\n",
    "Creating a **Jupyter Notebook** that incorporates examples and notes\n",
    "from the **tutorial** can be pretty handy. Later, when you want to look\n",
    "up a concept, you can also prototype your solution directly in the\n",
    "notebook.\n",
    "\n",
    "## Jupyter Notebooks\n",
    "\n",
    "> ** [What is a Notebook?](https://docs.jupyter.org/en/latest/)**\n",
    ">\n",
    "> A notebook is a shareable document that combines **computer code**,\n",
    "> **plain language descriptions**, **data**, **rich visualizations**\n",
    "> like **3D models**, **charts**, **graphs** and **figures**, and\n",
    "> **interactive controls**. A notebook, along with an editor (like\n",
    "> JupyterLab), provides a fast interactive environment for\n",
    "> **prototyping** and **explaining code**, **exploring and visualizing\n",
    "> data**, and **sharing ideas** with others.\n",
    "\n",
    "### Quick Start\n",
    "\n",
    "<a\n",
    "href=\"https://colab.research.google.com/github/turcotte/csi4106-f24/blob/main/notebooks/lectures/02/01_ottawa_river_temperature.ipynb\"\n",
    "class=\"external\" target=\"_blank\" data-fig-alt=\"Open in Colab\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
    "\n",
    "**Jupyter Notebooks** are widely utilized in the fields of data science\n",
    "and machine learning.\n",
    "\n",
    "Many of you are likely familiar with Jupyter Notebook and Google Colab\n",
    "environments. Please raise your hand if you are already users. This\n",
    "tutorial is specifically designed for those who are not yet familiar\n",
    "with these tools.\n",
    "\n",
    "Google Colab offers a convenient platform for writing and executing\n",
    "notebooks without requiring local installation.\n",
    "\n",
    "A notebook integrates plain language descriptions with source code and\n",
    "graphics. Without delving into the details of the document, observe the\n",
    "alternation between the descriptions, the source code, and the graphics.\n",
    "\n",
    "Your code runs within an environment called a kernel. In this notebook,\n",
    "we are using a Python kernel. Other popular kernels include Julia and R;\n",
    "see [Jupyter\n",
    "Kernels](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels) for\n",
    "more information.\n",
    "\n",
    "You can execute the entire notebook using Runtime → Run all. However, it\n",
    "is common to execute cells individually to read the corresponding\n",
    "instructions and observe the results. This also allows for code\n",
    "modifications to see the effects of changes.\n",
    "\n",
    "All cells share the same execution environment, making the order of\n",
    "execution critical. A cell that relies on variables or functions from\n",
    "another cell must be executed after the defining cell. In particular,\n",
    "always ensure that the necessary librairies are loaded first.\n",
    "\n",
    "**See also:** - [The Jupyter\n",
    "Notebook](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html)\n",
    "\n",
    "## Running Jupyter on your computer\n",
    "\n",
    "Assuming the notebook is in the current directory, execute the following\n",
    "command from the terminal.\n",
    "\n",
    "``` bash\n",
    "jupyter notebook 01_ottawa_river_temperature.ipynb\n",
    "```\n",
    "\n",
    "Similarly, to create a new notebook from scratch,\n",
    "\n",
    "``` bash\n",
    "jupyter notebook\n",
    "```\n",
    "\n",
    "The installation process for Jupyter and other environments will be\n",
    "covered later in this presentation.\n",
    "\n",
    "These commands launch a Jupyter server on your computer, listening on a\n",
    "local port and directing your browser to the specified local URL. The\n",
    "output will be something like this:\n",
    "\n",
    "    Jupyter Server 2.14.2 is running at:\n",
    "         http://localhost:8888/tree?token=94eca753b1887a460404d2b5eebb3b7a6211be0b839e9c34\n",
    "         http://127.0.0.1:8888/tree?token=94eca753b1887a460404d2b5eebb3b7a6211be0b839e9c34\n",
    "    Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "\n",
    "As you can see, executing a notebook locally is similar to running it in\n",
    "Google Colab. However, it requires that Jupyter and all necessary\n",
    "libraries (such as NumPy, pandas, and scikit-learn) be installed on your\n",
    "local system.\n",
    "\n",
    "In a new notebook:\n",
    "\n",
    "1.  Create an example showing how text and cells alternate.\n",
    "2.  Write an example showing how the order of execution matters.\n",
    "\n",
    "**See also:**\n",
    "\n",
    "-   [Running the\n",
    "    Notebook](https://docs.jupyter.org/en/latest/running.html)\n",
    "\n",
    "## Why?\n",
    "\n",
    "-   **Ease of Use:** The interface is intuitive and conducive to\n",
    "    exploratory analysis.\n",
    "\n",
    "-   **Visualization:** The capability to embed rich, interactive\n",
    "    visualizations directly within the notebook enhances its utility for\n",
    "    data analysis and presentation.\n",
    "\n",
    "-   **Reproducibility:** Jupyter Notebooks have become the de facto\n",
    "    standard in many domains for demonstrating code functionality and\n",
    "    ensuring reproducibility.\n",
    "\n",
    "## How?\n",
    "\n",
    "-   Google [**Colab**](https://colab.research.google.com)\n",
    "-   **Local** installation\n",
    "    -   In your **browser**\n",
    "        -   **Notebook** or **JupyterLab**\n",
    "    -   [**Visual Studio\n",
    "        Code**](https://code.visualstudio.com/docs/datascience/jupyter-notebooks)\n",
    "-   More options, including [**JupyterHub**](https://jupyter.org/hub) (a\n",
    "    multi-user version)\n",
    "\n",
    "Mastering new technology often requires time and patience. Recognize\n",
    "that your levels of experience may vary. Select the option that best\n",
    "aligns with your current expertise. Begin with simpler choices, knowing\n",
    "that you can revisit and adjust your decisions as you gain proficiency.\n",
    "\n",
    "For those comfortable with technology, JupyterLab may be the preferable\n",
    "choice. As the next-generation web-based interface for Jupyter projects,\n",
    "it offers an integrated development environment (IDE)-like experience\n",
    "with support for multiple tabs. Conversely, if you prefer a more\n",
    "straightforward starting point, Jupyter Notebook might be a better\n",
    "option.\n",
    "\n",
    "## Version Control (GitHub)\n",
    "\n",
    "By default, Jupyter Notebooks store the outputs of code cells, including\n",
    "media objects.\n",
    "\n",
    ". . .\n",
    "\n",
    "Jupyter Notebooks are JSON documents, and images within them are encoded\n",
    "in PNG base64 format.\n",
    "\n",
    ". . .\n",
    "\n",
    "This encoding can lead to several issues when using version control\n",
    "systems, such as GitHub.\n",
    "\n",
    "-   **Large File Sizes**: Jupyter Notebooks can become quite large due\n",
    "    to embedded images and outputs, leading to prolonged upload times\n",
    "    and potential storage constraints.\n",
    "-   **Incompatibility with Text-Based Version Control**: GitHub is\n",
    "    optimized for text-based files, and the inclusion of binary data,\n",
    "    such as images, complicates the process of tracking changes and\n",
    "    resolving conflicts. Traditional diff and merge operations are not\n",
    "    well-suited for handling these binary formats.\n",
    "\n",
    "## Version Control (GitHub) - solutions\n",
    "\n",
    "1.  In JupyterLab or Notebook, Edit $\\rightarrow$ Clear Outputs of All\n",
    "    Cells, then save.\n",
    "2.  On the command line, use `jupyter nbconvert --clear-output`\n",
    "\n",
    "``` bash\n",
    "jupyter nbconvert --clear-output --inplace 04_stock_price.ipynb\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "``` bash\n",
    "jupyter nbconvert 04_stock_price.ipynb --to notebook --ClearOutputPreprocessor.enabled=True --output 04_stock_price_clear\n",
    "```\n",
    "\n",
    "1.  Use `nbdime`, specialized for Jupyter Notebooks.\n",
    "\n",
    "For assignments, we will ask you to keep the outputs.\n",
    "\n",
    "When copying source code from slides or notebooks, click on the ‘Copy to\n",
    "Clipboard’ icon to ensure that only the plain text is copied, excluding\n",
    "any HTML formatting.\n",
    "\n",
    "## Installing Jupyter (1/2)\n",
    "\n",
    "These instructions use [`pip`](https://pip.pypa.io/en/stable/), [the\n",
    "recommended installation tool for\n",
    "Python](https://packaging.python.org/en/latest/guides/tool-recommendations/#installation-tool-recommendations).\n",
    "\n",
    "The initial step is to verify that you have a functioning Python\n",
    "installation with pip installed.\n",
    "\n",
    "### Linux/macOS\n",
    "\n",
    "``` bash\n",
    "$ python --version \n",
    "```\n",
    "\n",
    "    Python 3.10.14\n",
    "\n",
    "``` bash\n",
    "$ pip --version\n",
    "```\n",
    "\n",
    "    pip 24.2\n",
    "\n",
    "### Windows\n",
    "\n",
    "``` bash\n",
    "C:> py --version \n",
    "```\n",
    "\n",
    "    Python 3.10.14\n",
    "\n",
    "``` bash\n",
    "C:> py -m pip --version\n",
    "```\n",
    "\n",
    "    pip 24.2\n",
    "\n",
    "Consult the appendix for other options, including\n",
    "[conda](https://docs.conda.io/), [mamba](https://mamba.readthedocs.io/).\n",
    "and [pipenv](https://pipenv.pypa.io/).\n",
    "\n",
    "## Installing Jupyter (2/2)\n",
    "\n",
    "Installing `JupyterLab` with `pip`:\n",
    "\n",
    "``` bash\n",
    "$ pip install jupyterlab\n",
    "```\n",
    "\n",
    "Once installed, run `JupyterLab` with:\n",
    "\n",
    "``` bash\n",
    "$ jupyter lab\n",
    "```\n",
    "\n",
    "## Sample Jupyter Notebooks\n",
    "\n",
    "-   [01_ottawa_river_temperature](01_ottawa_river_temperature.html)\n",
    "    ([Jupyter Notebook](01_ottawa_river_temperature.ipynb))\n",
    "-   [02_empty](02_empty.html) ([Jupyter Notebook](02_empty.ipynb))\n",
    "-   [03_get_youtube_transcript](03_get_youtube_transcript.html)\n",
    "    ([Jupyter Notebook](03_get_youtube_transcript.ipynb))\n",
    "-   [04_stock_price](04_stock_price.html) ([Jupyter\n",
    "    Notebook](04_stock_price.ipynb))\n",
    "-   [05_central_limit](05_central_limit.html) ([Jupyter\n",
    "    Notebook](05_central_limit.ipynb))\n",
    "\n",
    "## Missing libraries\n",
    "\n",
    "Launching `03_get_youtube_transcript` in Colab.\n",
    "\n",
    "<a\n",
    "href=\"https://colab.research.google.com/github/turcotte/csi4106-f24/blob/main/notebooks/lectures/02/03_get_youtube_transcript.ipynb\"\n",
    "class=\"external\" target=\"_blank\" data-fig-alt=\"Open in Colab\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
    "\n",
    "What to do when libraries are missing in Google Colab?\n",
    "\n",
    "## `04_stock_price`\n",
    "\n",
    "Launching `04_stock_price` in Colab.\n",
    "\n",
    "<a\n",
    "href=\"https://colab.research.google.com/github/turcotte/csi4106-f24/blob/main/notebooks/lectures/02/04_stock_price.ipynb\"\n",
    "class=\"external\" target=\"_blank\" data-fig-alt=\"Open in Colab\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
    "\n",
    "## `05_central_limit`\n",
    "\n",
    "Launching `05_central_limit` in Colab.\n",
    "\n",
    "<a\n",
    "href=\"https://colab.research.google.com/github/turcotte/csi4106-f24/blob/main/notebooks/lectures/02/05_central_limit.ipynb\"\n",
    "class=\"external\" target=\"_blank\" data-fig-alt=\"Open dans Colab\"><img\n",
    "src=\"https://colab.research.google.com/assets/colab-badge.svg\" /></a>\n",
    "\n",
    "# Prologue\n",
    "\n",
    "## Summary\n",
    "\n",
    "-   **Situate** current AI within its historical context.\n",
    "-   **Introducing** the tools, specifically Jupyter Notebooks.\n",
    "\n",
    "## Next lecture\n",
    "\n",
    "-   Introduction to machine learning\n",
    "\n",
    "## One of my favourite ML books\n",
    "\n",
    "![](https://m.media-amazon.com/images/I/81qHV3ACapL._AC_UF1000,1000_QL80_.jpg)\n",
    "\n",
    "-   **[Hands-on Machine Learning with Scikit-Learn, Keras, and\n",
    "    TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)**\n",
    "    (Géron 2022) provides practical examples and leverages\n",
    "    production-ready Python frameworks.\n",
    "    -   Comprehensive coverage includes not only the models but also\n",
    "        libraries for hyperparameter tuning, data preprocessing, and\n",
    "        visualization.\n",
    "    -   [Code examples and solutions to\n",
    "        exercises](https://github.com/ageron/handson-ml3) available as\n",
    "        Jupyter Notebooks on GitHub.\n",
    "    -   [Aurélien Géron](https://www.linkedin.com/in/aurelien-geron) is\n",
    "        a former YouTube Product Manager, who lead video classification\n",
    "        for Search & Discovery.\n",
    "\n",
    "## Resources\n",
    "\n",
    "-   [Project Jupyter Documentation](https://docs.jupyter.org/en/latest/)\n",
    "-   [Google Colab](https://colab.google)\n",
    "-   [Colab\n",
    "    Primer](https://colab.research.google.com/github/google/picatrix/blob/main/notebooks/Quick_Primer_on_Colab_Jupyter.ipynb)\n",
    "-   [Pandas in 10 minutes](https://www.youtube.com/watch?v=_T8LGqJtuGc)\n",
    "    (video)\n",
    "\n",
    "## References\n",
    "\n",
    "Boser, Bernhard E., Isabelle Guyon, and Vladimir Vapnik. 1992. “A\n",
    "Training Algorithm for Optimal Margin Classifiers.” In *COLT*, 144–52.\n",
    "ACM. <https://doi.org/10.1145/130385.130401>.\n",
    "\n",
    "Chomsky, Noam. 1956. “Three Models for the Description of Language.”\n",
    "*IRE Transactions on Information Theory* 2: 113–24.\n",
    "\n",
    "Church, Alonzo. 1936. “An Unsolvable Problem of Elementary Number\n",
    "Theory.” *American Journal of Mathematics* 58 (2): 345–63.\n",
    "<https://doi.org/10.2307/2371045>.\n",
    "\n",
    "Conroy, Gemma. 2023. “<span class=\"nocase\">This is the largest map of\n",
    "the human brain ever made</span>.” *Nature* 622 (7984): 679–80.\n",
    "<https://doi.org/10.1038/d41586-023-03192-2>.\n",
    "\n",
    "Cook, Stephen A. 1971. “The Complexity of Theorem-Proving Procedures.”\n",
    "In *Proceedings of the Third Annual ACM Symposium on Theory of\n",
    "Computing*, 151–58. STOC ’71. New York, NY, USA: Association for\n",
    "Computing Machinery. <https://doi.org/10.1145/800157.805047>.\n",
    "\n",
    "Craik, K. J. W. 1943. *The Nature of Explanation*. Cambridge University\n",
    "Press. <https://books.google.ca/books?id=EN0TrgEACAAJ>.\n",
    "\n",
    "Géron, Aurélien. 2022. *Hands-on Machine Learning with Scikit-Learn,\n",
    "Keras, and TensorFlow*. 3rd ed. O’Reilly Media, Inc.\n",
    "\n",
    "Hume, David. (1739) 1739. *A Treatise of Human Nature*. Edited by L. A.\n",
    "Selby-Bigge. Oxford: Oxford University Press.\n",
    "\n",
    "Karp, Richard M. 1972. “Reducibility Among Combinatorial Problems.” In\n",
    "*Complexity of Computer Computations*, edited by Raymond E. Miller and\n",
    "James W. Thatcher, 85–103. The IBM Research Symposia Series. Plenum\n",
    "Press, New York. <http://dblp.uni-trier.de/db/conf/coco/cocc1972.html>.\n",
    "\n",
    "Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. “ImageNet\n",
    "Classification with Deep Convolutional Neural Networks.” In *Advances in\n",
    "Neural Information Processing Systems*, edited by F. Pereira, C. J.\n",
    "Burges, L. Bottou, and K. Q. Weinberger. Vol. 25. Curran Associates,\n",
    "Inc.\n",
    "<https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf>.\n",
    "\n",
    "Maroso, Mattia. 2023. “A Quest into the Human Brain.” *Science* 382\n",
    "(6667): 166–67. <https://doi.org/10.1126/science.adl0913>.\n",
    "\n",
    "McCorduck, Pamela. 2004. *<span class=\"nocase\">Machines Who Think, A\n",
    "Personal Inquiry into the History and Prospects of Artificial\n",
    "Intelligence</span>*. Taylor & Francis Group, LLC.\n",
    "<https://doi.org/10.1201/9780429258985>.\n",
    "\n",
    "McCulloch, Warren S., and Walter Pitts. 1943. “A Logical Calculus of the\n",
    "Ideas Immanent in Nervous Activity.” *The Bulletin of Mathematical\n",
    "Biophysics* 5 (4): 115–33. <https://doi.org/10.1007/BF02478259>.\n",
    "\n",
    "Miller, George A. 1956. “The Magical Number Seven, Plus or Minus Two:\n",
    "Some Limits on Our Capacity for Processing Information.” *The\n",
    "Psychological Review* 63 (2): 81–97.\n",
    "\n",
    "Mitchell, Melanie. 2019. *Artificial Intelligence: A Guide for Thinking\n",
    "Humans*. New York, NY, USA: Farrar, Straus; Giroux.\n",
    "\n",
    "———. 2024. “The Turing Test and Our Shifting Conceptions of\n",
    "Intelligence.” *Science* 385 (6710): eadq9356.\n",
    "<https://doi.org/10.1126/science.adq9356>.\n",
    "\n",
    "Newell, Allen, and Herbert A. Simon. 1976. “Computer Science as\n",
    "Empirical Inquiry: Symbols and Search.” *Commun. ACM* 19 (3): 113–26.\n",
    "<https://doi.org/10.1145/360018.360022>.\n",
    "\n",
    "Newell, A., and H. Simon. 1956. “The Logic Theory Machine–a Complex\n",
    "Information Processing System.” *IRE Transactions on Information Theory*\n",
    "2 (3): 61–79. <https://doi.org/10.1109/TIT.1956.1056797>.\n",
    "\n",
    "Russell, Stuart, and Peter Norvig. 2020. *Artificial Intelligence: A\n",
    "Modern Approach*. 4th ed. Pearson. <http://aima.cs.berkeley.edu/>.\n",
    "\n",
    "Samuel, A. L. 1959. “Some Studies in Machine Learning Using the Game of\n",
    "Checkers.” *IBM J. Res. Dev.* 3 (3): 210–29.\n",
    "<https://doi.org/10.1147/rd.33.0210>.\n",
    "\n",
    "Strickland, Eliza. 2021. “The Turbulent Past and Uncertain Future of AI:\n",
    "Is There a Way Out of AI’s Boom-and-Bust Cycle?” *IEEE Spectrum* 58\n",
    "(10): 26–31. <https://doi.org/10.1109/MSPEC.2021.9563956>.\n",
    "\n",
    "Turing, A M. 1950. “<span class=\"nocase\">Computing machinery and\n",
    "intelligence</span>.” *Mind* 59: 433–60.\n",
    "\n",
    "Turing, Alan M. 1936. “On Computable Numbers, with an Application to the\n",
    "Entscheidungsproblem.” *Proceedings of the London Mathematical Society*\n",
    "2 (42): 230–65.\n",
    "\n",
    ":::\n",
    "\n",
    "# Appendix: environment management\n",
    "\n",
    "## Environment management\n",
    "\n",
    "> **Important**\n",
    ">\n",
    "> Do not attempt to install these tools unless you are confident in your\n",
    "> technical skills. An incorrect installation could waste significant\n",
    "> time or even render your environment unusable. There is nothing wrong\n",
    "> with using `pip` or [Google Colab](https://colab.research.google.com)\n",
    "> for your coursework. You can develop these installation skills later\n",
    "> without impacting your grades.\n",
    "\n",
    "## Package management\n",
    "\n",
    "-   Managing package dependencies can be complex.\n",
    "    -   A package manager addresses these challenges.\n",
    "-   Different projects may require different versions of the same\n",
    "    libraries.\n",
    "    -   Package management tools, such as `conda`, facilitate the\n",
    "        creation of virtual environments tailored to specific projects.\n",
    "\n",
    "## Anaconda\n",
    "\n",
    "[Anaconda](https://www.anaconda.com) is a comprehensive package\n",
    "management platform for Python and R. It utilizes\n",
    "[Conda](https://docs.conda.io/en/latest/) to manage packages,\n",
    "dependencies, and environments.\n",
    "\n",
    "-   **Anaconda** is advantageous as it comes pre-installed with over 250\n",
    "    popular packages, providing a robust starting point for users.\n",
    "\n",
    "-   However, this extensive distribution results in a large file size,\n",
    "    which can be a drawback.\n",
    "\n",
    "-   Additionally, since Anaconda relies on `conda`, it also inherits the\n",
    "    limitations and issues associated with `conda` (see subsequent\n",
    "    slides).\n",
    "\n",
    "## Miniconda\n",
    "\n",
    "[**Miniconda**](https://docs.anaconda.com/miniconda/) is a minimal\n",
    "version of Anaconda that includes only `conda`, Python, their\n",
    "dependencies, and a small selection of essential packages.\n",
    "\n",
    "## Conda\n",
    "\n",
    "[Conda](https://conda.io/projects/conda/en/latest/index.html) is an\n",
    "open-source package and environment management system for Python and R.\n",
    "It facilitates the installation and management of software packages and\n",
    "the creation of isolated virtual environments.\n",
    "\n",
    "-   Dependency\n",
    "    [conflicts](https://community.anaconda.cloud/t/universal-way-of-approaching-package-conflicts/64289)\n",
    "    due to complex package interdependencies can force the user\n",
    "    reinstall Anaconda/Conda.\n",
    "\n",
    "-   Plague with large storage requirements and performance issues during\n",
    "    package resolution.\n",
    "\n",
    "## Mamba\n",
    "\n",
    "[Mamba](https://github.com/mamba-org/mamba) is a reimplementation of the\n",
    "`conda` package manager in C++.\n",
    "\n",
    "-   It is significantly faster than `conda`.\n",
    "-   It consumes fewer computational resources.\n",
    "-   It provides clearer and more informative error messages.\n",
    "-   It is fully compatible with `conda`, making it a viable replacement.\n",
    "\n",
    "[Micromamba](https://mamba.readthedocs.io/en/latest/installation/micromamba-installation.html)\n",
    "is a fully statically-linked, self-contained executable. Its empty base\n",
    "environment ensures that the base is never corrupted, eliminating the\n",
    "need for reinstallation.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "Marcel **Turcotte**\n",
    "\n",
    "<Marcel.Turcotte@uOttawa.ca>\n",
    "\n",
    "School of Electrical Engineering and **Computer Science** (EE**CS**)\n",
    "\n",
    "University of Ottawa"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
